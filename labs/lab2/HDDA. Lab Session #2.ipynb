{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Session #2\n",
    "## 28/08/2018\n",
    "___\n",
    "### Objectives:\n",
    "- OLS (numpy)\n",
    "- Work with Data (pandas)\n",
    "    - Creation\n",
    "    - Exploration\n",
    "    - Visualization\n",
    "- Signal processing\n",
    "    - Convolution and correlation\n",
    "    - Convolution of distributions\n",
    "    - Correlation and covariance\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHECK YOUR PYTHON VERSION\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "- sys\n",
    "- warnings\n",
    "- numpy\n",
    "- matplotlib\n",
    "- statsmodels\n",
    "- pandas\n",
    "- scipy\n",
    "- math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, let's disable warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a [magic fucntion](https://ipython.readthedocs.io/en/stable/interactive/tutorial.html#magics-explained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First step: add packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add column of 1's for intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# add constant for intercept\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use statsmodels implementation of Ordinary Least Squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now plot the line along with the error (+/- sigma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def line(x, a, b):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "1. Implement closed formula solution fo the parameters of Linear Regression (from lecture notes). \n",
    "1. Implement formula for coefficient of determination (R-squared)\n",
    "\n",
    "Feel free to use any library, as default - use [numpy.linalg](https://docs.scipy.org/doc/numpy/reference/routines.linalg.html).\n",
    "\n",
    "Compare results with OLS method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here goes your solution for LR parameters\n",
    "import numpy.linalg as nli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here goes your solution for R-squared\n",
    "SSres = 0\n",
    "SStot = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Representation\n",
    "\n",
    "**Pandas** in an open-source python package that is great for data structuring, preparation and analysis.\n",
    "\n",
    "Features:\n",
    "- Unified data representation using *DataFrame* objects - 2D heterogeneous tables with labeled axes;\n",
    "- Database-like operations: join, union(append), group by, sort, column selection, filtering;\n",
    "- Advanced operations: pivoting, reshaping, multi-indexing;\n",
    "- Basic statistics: count, mean, std, min/max, quantiles;\n",
    "- Vizualization with matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Dataframe creation\n",
    "Create dataframe by reading a csv file with brain size data (analyzed [here](https://www.researchgate.net/profile/Robert_Schultz2/publication/222881180_In_vivo_brain_size_and_intelligence_Intelligence_15_223-228/links/00b4952d94932772d4000000.pdf)).\n",
    "The csv contains following columns:\n",
    "1. Gender: Male or Female\n",
    "1. FSIQ: Full Scale IQ scores \n",
    "1. VIQ: Verbal IQ scores \n",
    "1. PIQ: Performance IQ scores \n",
    "1. Weight: body weight in pounds\n",
    "1. Height: height in inches\n",
    "1. MRI_Count: total pixel Count from the 18 MRI scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to create dataset from dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sin_t cos_t \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Data exploration\n",
    "Let's consider simple operations to operate with dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Gender' column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use boolean indexing to filter rows. For example to compute the *mean value* of verbal IQ score for females it is possible to use the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean data[]['VIQ'] for data['Gender'] == 'Female' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get simple statistics for each column use `descibe` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `groupby` operation allows to split dataframe into groups. \n",
    "\n",
    "It returns `GroupBy` object which can be used to apply a function for each group separately ([more](https://pandas.pydata.org/pandas-docs/stable/cookbook.html#cookbook-grouping) documentation on grouping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean for groupby_gender \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby_gender.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\t•\tWhat is the mean value for VIQ for the full population?\n",
    "\t•\tHow many males/females were included in this study? \n",
    "\t•\tWhat is the average value of MRI counts expressed in log units, for males and females?\n",
    "**Hint**: use ‘tab completion’ to find out the methods that can be called, instead of `mean` in the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print mean VIQ for the full population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the numbers of males and females\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print average MRI counts in log units for each gender\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Data visualization\n",
    "Let's use pandas plotting to make simple boxplots and 3x3 matrix of scatter plots for 3 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots of different columns for each gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas.tools.plotting import scatter_matrix\n",
    "#scatter_matrix(data[['Weight', 'Height', 'MRI_Count']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter_matrix(data[['FSIQ', 'VIQ', 'PIQ']])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Plot the scatter matrix for males only, and for females only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter matrix for males\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter matrix for females \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Signal processing\n",
    "\n",
    "#### 3.1 Convolution and correlation\n",
    "\n",
    "From the point of view of signal processing convolution and correlation are very similar operations. They are defined as following\n",
    "\n",
    "Convolution:\n",
    "$$ (f*g)(y) = \\int\\limits_{-\\infty}^{\\infty} f(x)g(y-x)dx$$\n",
    "Cross-correlation:\n",
    "$$ (f\\star g)(y) = \\int\\limits_{-\\infty}^{\\infty} f(x)g(y+x)dx$$\n",
    "\n",
    "If `g(x)` is symmetric then the convolution and cross-correlation are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a numpy array with square-shaped signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100 # sample count\n",
    "startX = 40  \n",
    "endX = 60\n",
    "x = np.arange(N)\n",
    "x = ((x < endX) * (x> startX))*10\n",
    "plt.plot(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a triangular signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(100)\n",
    "heightY = 1.0\n",
    "startY = 20\n",
    "endY=80\n",
    "widthY = (endY-startY)/2.0\n",
    "for i in range(startY,int(N/2)):\n",
    " y[i] =  (i-startY) * (heightY / widthY) \n",
    "for i in range(int(N/2),endY):\n",
    " y[i] = 2*heightY - ((i-startY) * (heightY / widthY))\n",
    "plt.plot(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply two operations on the inputs and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve\n",
    "x_conv = convolve(x,y,'same')\n",
    "plt.plot(x_conv);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import correlate\n",
    "x_corr = correlate(x,y,'same')\n",
    "plt.plot(x_corr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, the result of convolution for symmetric kernel is the same as result of correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "Try these two operations with the non-symetric kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Convolution of distributions\n",
    "In statistics convolution plays important role.\n",
    "\n",
    "The distribution of the *sum of two independent variables* is the convolution of the distributions.\n",
    "\n",
    "I.e. if we consider two independent continuous random variables `X` and `Y` with PDFs `f` and `g` the PDF of their sum (X+Y) will be computed as: \n",
    "\n",
    "$$ d(x) = (f * g)(x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get an interesting result if we consider the sum of several random variables with identical distributions, i.e. convolution of a distribution with itself several times.\n",
    "2\n",
    "For example, let's take a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "orig = np.random.uniform(0,10,1200)\n",
    "h = plt.hist(orig, bins=120, normed=True);\n",
    "orig = h[0]\n",
    "t = h[1]\n",
    "xconv = np.copy(orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "ax = plt.subplot(2, 3, 1)\n",
    "ax.set_title(\"f\")\n",
    "ax.plot(t[:-1], orig);\n",
    "for i in range(5):\n",
    "    xconv = convolve(orig, xconv)\n",
    "    ax = plt.subplot(2, 3, i+2)\n",
    "    ax.set_title((\"f*\"*(i+2))[:-1])\n",
    "    ax.plot(xconv);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an illustration of Central Limit Theorem: the distribution of the sum of random variables which are iid (independent identically distributed) has a form of a Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Correlation and covariance\n",
    "\n",
    "In statistics the linear correlation between two variables X and Y can be measured using Pearson correlation coefficient:\n",
    "\n",
    "$$ corr(x,y) = \\frac{\\sum\\limits_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt {\\sum\\limits_{i=1}^n(x_i-\\bar{x})^2\\sum\\limits_{i=1}^n(y_i-\\bar{y})^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('examples/brain_size.csv', sep=';', na_values=\".\")\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unnormalized version of the correlation coefficient is the measure of joint variability - **covariance**.\n",
    "$$ cov(x,y) = \\frac{1}{n-1}\\sum\\limits_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the correlation and covariance always have the same sign which shows the tendency in the linear relationship between variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now consider more closely the correlation between `Height` and `Weight` of the people from experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy \n",
    "scipy.stats.pearsonr(data['Height'], data['Weight'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['Height'], data['Weight']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Let's compare the difference in the definition of **correlation** from the signal processing point of view and from the point of view of statistics.\n",
    "\n",
    "1. Compute the correlation from `scipy.signal` package of demeaned signals. Divide by the number of observations - 1.\n",
    "2. Compute the covariance using `numpy` or any other package. Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute demeaned correlation divided by n-1 using scipy.signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute covariance using numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "1. Implement the computation of Pearson correlation coefficient. \n",
    "1. Implement calculation of **t-statistics**, and **p-value** for the correlation coefficient. Add p-value to return value of the function.\n",
    "1. Compare results with `scipy` implementation for `Height` and `Weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from math import sqrt\n",
    "# def pearsonr(x, y):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
